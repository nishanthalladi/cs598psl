---
title: "Project1"
author: "Ethan Cook"
date: "2023-09-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Error calculation function
```{r}
library(DescTools)
library(fastDummies)

calc_RMSE = function(predictions, actuals)
{
  n = length(actuals)
  sqrt((1 / n) * sum((log(predictions) - log(actuals)) ^ 2))
}

```

### Load train data
```{r}
train_f1 = read.csv("fold1/train.csv", stringsAsFactors = FALSE)
train_f2 = read.csv("fold2/train.csv", stringsAsFactors = FALSE)
train_f3 = read.csv("fold3/train.csv", stringsAsFactors = FALSE)
train_f4 = read.csv("fold4/train.csv", stringsAsFactors = FALSE)
train_f5 = read.csv("fold5/train.csv", stringsAsFactors = FALSE)
train_f6 = read.csv("fold6/train.csv", stringsAsFactors = FALSE)
train_f7 = read.csv("fold7/train.csv", stringsAsFactors = FALSE)
train_f8 = read.csv("fold8/train.csv", stringsAsFactors = FALSE)
train_f9 = read.csv("fold9/train.csv", stringsAsFactors = FALSE)
train_f10 = read.csv("fold10/train.csv", stringsAsFactors = FALSE)

train = train_f7 # TODO remove after testing
```

### Remove unwanted predictors from train
```{r}
train = subset(train, select = -c(Street, Utilities, Condition_2, Roof_Matl, Heating, Pool_QC, Misc_Feature, Low_Qual_Fin_SF, Pool_Area, Longitude, Latitude) )
```

```{r}
categorical.vars = colnames(train)[
    which(sapply(train,
                   function(x) mode(x)=="character"))]

cat_only = subset(train, select=c(categorical.vars))
modes_ = apply(cat_only, 2, Mode)

removeable_cols = c()
for(i in 1:ncol(cat_only))
{
  n = nrow(cat_only)
  sum_of_modes = sum(cat_only[,i] == modes_[i])
  if(sum_of_modes / n > 0.95)
  {
    removeable_cols = c(removeable_cols, i)
  }
}

removeable_names = colnames(cat_only[removeable_cols])
train = train[,!(colnames(train)) %in% removeable_names]
```


### Winzorize train data
```{r}
train$Lot_Frontage = Winsorize(train$Lot_Frontage, minval = 0)
train$Lot_Area = Winsorize(train$Lot_Area, minval = 0)
train$Mas_Vnr_Area = Winsorize(train$Mas_Vnr_Area, minval = 0)
train$BsmtFin_SF_2 = Winsorize(train$BsmtFin_SF_2, minval = 0)
train$Bsmt_Unf_SF = Winsorize(train$Bsmt_Unf_SF, minval = 0)
train$Total_Bsmt_SF = Winsorize(train$Total_Bsmt_SF, minval = 0)
train$Second_Flr_SF = Winsorize(train$Second_Flr_SF, minval = 0)
train$First_Flr_SF = Winsorize(train$First_Flr_SF, minval = 0)
train$Gr_Liv_Area = Winsorize(train$Gr_Liv_Area, minval = 0)
train$Garage_Area = Winsorize(train$Garage_Area, minval = 0)
train$Wood_Deck_SF = Winsorize(train$Wood_Deck_SF, minval = 0)
train$Open_Porch_SF = Winsorize(train$Open_Porch_SF, minval = 0)
train$Enclosed_Porch = Winsorize(train$Enclosed_Porch, minval = 0)
train$Three_season_porch = Winsorize(train$Three_season_porch, minval = 0)
train$Screen_Porch = Winsorize(train$Screen_Porch, minval = 0)
train$Misc_Val = Winsorize(train$Misc_Val, minval = 0)
```

```{r}
categoricalize = function(dataset)
{
  data.x = subset(dataset, select = -c(PID) ) # data without "PID" and "Sale_Price"
  
  # replace missing by zero
  data.x$Garage_Yr_Blt[is.na(data.x$Garage_Yr_Blt)] = 0
  
  categorical.vars = colnames(data.x)[
    which(sapply(data.x,
                   function(x) mode(x)=="character"))]
  
  data.dummy.cols = dummy_cols(data.x, select_columns = categorical.vars, remove_selected_columns = TRUE)
  
  processed.matrix = data.dummy.cols[order(names(data.dummy.cols))]
  processed.matrix
}
```


### Process categorical train data
```{r}
train.y = log(train$Sale_Price) # log transformed "Sale_Price"
train.x = categoricalize(subset(train, select = -c(Sale_Price) ))
train.names = colnames(train.x)
```


### Load test data
```{r}
test_f1 = read.csv("fold1/test.csv", stringsAsFactors = FALSE) 
test_f2 = read.csv("fold2/test.csv", stringsAsFactors = FALSE) 
test_f3 = read.csv("fold3/test.csv", stringsAsFactors = FALSE) 
test_f4 = read.csv("fold4/test.csv", stringsAsFactors = FALSE) 
test_f5 = read.csv("fold5/test.csv", stringsAsFactors = FALSE) 
test_f6 = read.csv("fold6/test.csv", stringsAsFactors = FALSE) 
test_f7 = read.csv("fold7/test.csv", stringsAsFactors = FALSE) 
test_f8 = read.csv("fold8/test.csv", stringsAsFactors = FALSE) 
test_f9 = read.csv("fold9/test.csv", stringsAsFactors = FALSE) 
test_f10= read.csv("fold10/test.csv", stringsAsFactors = FALSE)


test_y_f1 = read.csv("fold1/test_y.csv", stringsAsFactors = FALSE)
test_y_f2 = read.csv("fold2/test_y.csv", stringsAsFactors = FALSE)
test_y_f3 = read.csv("fold3/test_y.csv", stringsAsFactors = FALSE)
test_y_f4 = read.csv("fold4/test_y.csv", stringsAsFactors = FALSE)
test_y_f5 = read.csv("fold5/test_y.csv", stringsAsFactors = FALSE)
test_y_f6 = read.csv("fold6/test_y.csv", stringsAsFactors = FALSE)
test_y_f7 = read.csv("fold7/test_y.csv", stringsAsFactors = FALSE)
test_y_f8 = read.csv("fold8/test_y.csv", stringsAsFactors = FALSE)
test_y_f9 = read.csv("fold9/test_y.csv", stringsAsFactors = FALSE)
test_y_f10= read.csv("fold10/test_y.csv", stringsAsFactors = FALSE)

test = test_f7
test_y = test_y_f7 # TODO remove after testing
```

### Process categorical test data
```{r}
test.x = categoricalize(test)
test.names = colnames(test.x)

# train.names was saved during train data processing
testonly <- setdiff(test.names, train.names)
trainonly <- setdiff(train.names, test.names)

df = data.frame(matrix(0, nrow = dim(test.x)[1], ncol = length(trainonly)))
colnames(df) = trainonly

all_columns = cbind(test.x, df)
test.x = all_columns[ , !(names(all_columns) %in% testonly)]
test.x = test.x[order(names(test.x))]

set.seed(1776)
```

# Linear Regression Model

```{r}
library(glmnet)

# Just elastic net
cvfit = cv.glmnet(as.matrix(train.x), train.y, alpha = 0.5)
pred_y = as.vector(exp(predict(cvfit, as.matrix(test.x))))

print(calc_RMSE(pred_y, test_y$Sale_Price))
```

```{r}
# Lasso variable selection
cvfit = cv.glmnet(as.matrix(train.x), train.y, alpha = 1)

reduced_predictors = names(coef(cvfit)[rowSums(coeffs) != 0, ])
reduced_predictors = reduced_predictors[-1]

pred_y = as.vector(exp(predict(cvfit, as.matrix(test.x))))
print(calc_RMSE(pred_y, test_y$Sale_Price))

# Ridge based off Lasso var selection
cvfit = cv.glmnet(as.matrix(subset(train.x, select = c(reduced_predictors))), train.y, alpha = 0, family='gaussian')
pred_y = as.vector(exp(predict(cvfit, as.matrix(subset(test.x, select = c(reduced_predictors))))))

print(calc_RMSE(pred_y, test_y$Sale_Price))

```


```{r}
# Just Ridge
cvfit = cv.glmnet(as.matrix(train.x), train.y, alpha = 0, family='gaussian')
pred_y = as.vector(exp(predict(cvfit, as.matrix(test.x))))

print(calc_RMSE(pred_y, test_y$Sale_Price))

```



# XGBoost model
```{r, results = 'hide'}
require(xgboost)
dtrain <- xgb.DMatrix(data =data.matrix(train.x), label = data.matrix(train.y))
bstSparse <- xgboost(data = dtrain, eta=.05, subsample = .5 , nrounds=5000)
```

```{r}
dtest <- xgb.DMatrix(data = data.matrix(test.x))
pred_y = predict(bstSparse, dtest)

calc_RMSE(exp(pred_y), test_y$Sale_Price)
```


